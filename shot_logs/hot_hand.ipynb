{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c294bb99-80f4-44ab-81a9-6766b4539de8",
   "metadata": {},
   "source": [
    "# Personal Contribution\n",
    "### Synthetic Feature\n",
    "In this notebook i create a synthetic feature called 'HOT_HAND' which is a measure of the palyer's confidence.  \n",
    "We are then using the feature withthe machine learning model used previously in our inference task and hope to get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f7c012a-2297-413e-8e2e-1dd85fb88650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('fivethirtyeight')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#Inference task imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Logistic reg\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "\n",
    "#Neural net\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dabaa8f-6094-4ab2-aaf7-99d9cd4c2090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128069, 21)\n"
     ]
    }
   ],
   "source": [
    "shots = pd.read_csv('shot_logs.csv', header=0)\n",
    "print(shots.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbf9f45-2f59-4d25-b8c4-912dacd9098d",
   "metadata": {},
   "source": [
    "This function should return a series of the game cumulative points of the player at the moment of the shot.  \n",
    "I will be using this for my feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a7e7c6b-9b58-4bee-96db-ff2787ba6a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_points(df):\n",
    "    cumul = np.zeros(128069)\n",
    "    for i in range(128069):\n",
    "        num_shot = df.iloc[i,5]\n",
    "        for j in range(num_shot):\n",
    "            cumul[i] += df.iloc[i-j,17]\n",
    "    return cumul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cd9d12b-13f7-40eb-8d84-7b83bea7877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shots['PTS_CUMUL'] = cumulative_points(shots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cbe1d4-5753-43da-95c8-8f15bec49832",
   "metadata": {},
   "source": [
    "The feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f244e28c-ff7b-43ed-9a17-5d2b3c85cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = (shots['PTS_CUMUL']/(shots['SHOT_NUMBER']*3))\n",
    "shots['HOT_HAND'] = confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de39d60-6eda-466b-be8c-a5f6969cf93e",
   "metadata": {},
   "source": [
    "Next is the inference task withthe feature after some data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66c348f6-815d-4827-a495-bf6571e9f2b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['NEXT_SHOT_RESULT'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31580\\1406655625.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshots\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'GAME_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MATCHUP'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CLOSEST_DEFENDER_PLAYER_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'FGM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PTS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'player_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NEXT_SHOT_RESULT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Location'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'W'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Margin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Shot_No'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Period'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Game_Clock'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Shot_Clock'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Dribbles'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Touch_Time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Shot_Dist'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Pts_Type'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Shot_Result'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Closest_Defender'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Close_Def_Dist'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Player_Name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PTS_CUMUL'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'HOT_HAND'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4955\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4956\u001b[0m         \"\"\"\n\u001b[1;32m-> 4957\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4958\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4959\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4266\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4267\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4310\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4311\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4312\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6659\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6660\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6661\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6662\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6663\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['NEXT_SHOT_RESULT'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#Cleaning data\n",
    "\n",
    "df = shots\n",
    "\n",
    "df = df.drop(['GAME_ID', 'MATCHUP', 'CLOSEST_DEFENDER_PLAYER_ID', 'FGM', 'PTS', 'player_id', 'NEXT_SHOT_RESULT'], axis=1)\n",
    "\n",
    "df.columns = ['Location', 'W', 'Margin', 'Shot_No', 'Period', 'Game_Clock', 'Shot_Clock', 'Dribbles', 'Touch_Time', 'Shot_Dist', 'Pts_Type', 'Shot_Result', 'Closest_Defender', 'Close_Def_Dist', 'Player_Name', 'PTS_CUMUL', 'HOT_HAND']\n",
    "\n",
    "df['Shot_Result'] = np.where(df['Shot_Result'] == 'made', 1, 0)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df['W'] = df['W'].map({'W': 1, 'L': 0})\n",
    "\n",
    "df['Location'] = df['Location'].map({'H': 1, 'A': 0})\n",
    "\n",
    "df=df[df['Touch_Time']>0]\n",
    "\n",
    "df['Game_Clock'] = df['Game_Clock'].apply(lambda x: 60*int(x.split(':')[0]) + int(x.split(':')[1]))\n",
    "\n",
    "df['Game_Clock'] = (720-df['Game_Clock']) + (df['Period']-1)*720\n",
    "\n",
    "df = df.drop(['Period'], axis=1)\n",
    "\n",
    "df.to_csv(\"cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71ff8c-b1e4-4b2c-9468-45f22daaab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y\n",
    "X = df.drop(['Margin', 'Shot_Result', 'Player_Name', 'Closest_Defender'], axis=1)\n",
    "y = df['Shot_Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f9c9c3-d264-447f-aba6-9894643b2842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a model and train it (Logistic Regression)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model (Accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Obtain the formula and weights used\n",
    "intercept = lr.intercept_[0]\n",
    "coefficients = lr.coef_[0]\n",
    "formula = f\"y = {intercept} + \"\n",
    "for feature, coef in zip(X.columns, coefficients):\n",
    "    formula += f\"({coef} * {feature}) + \"\n",
    "formula = formula[:-3]  # Remove the last '+'\n",
    "print(\"Formula:\", formula)\n",
    "print(\"Weights:\", coefficients)\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': lr.coef_[0]})\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da84a4d3-22c0-408d-b04a-8dd597294004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a model and train it (Decision Trees)\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Print the formula and weights used\n",
    "tree_rules = export_text(dt, feature_names=X_train.columns.tolist())\n",
    "#print(tree_rules)\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model (Accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Get feature importances\n",
    "importances = dt.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importances = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values('importance', ascending=False)\n",
    "print(feature_importances)\n",
    "\n",
    "# Get feature sensitivities\n",
    "sensitivities = []\n",
    "for feature in feature_names:\n",
    "    X_test_copy = X_test.copy()\n",
    "    X_test_copy[feature] = X_test_copy[feature].mean()\n",
    "    y_pred = dt.predict(X_test_copy)\n",
    "    sensitivity = accuracy_score(y_test, y_pred)\n",
    "    sensitivities.append(sensitivity)\n",
    "feature_sensitivities = pd.DataFrame({'feature': feature_names, 'sensitivity': sensitivities}).sort_values('sensitivity', ascending=False)\n",
    "print(feature_sensitivities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c141bced-f099-4076-94ce-21c91b627967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Net\n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a neural network regressor\n",
    "regressor = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=100, random_state=42)\n",
    "\n",
    "# Train the regressor on the training data and track the lowest MSE\n",
    "lowest_mse = float('inf')\n",
    "best_regressor = None\n",
    "\n",
    "mse_scores = []\n",
    "for i in range(1, 20):\n",
    "    regressor.partial_fit(X_train_scaled, y_train)\n",
    "    y_pred = regressor.predict(X_train_scaled)\n",
    "    mse = mean_squared_error(y_train, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "    \n",
    "    if mse < lowest_mse:\n",
    "        lowest_mse = mse\n",
    "        best_regressor = regressor\n",
    "\n",
    "# Make predictions on the testing data using the best regressor\n",
    "y_pred_test = best_regressor.predict(X_test_scaled)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Plot the MSE scores over iterations\n",
    "plt.plot(range(1, 20), mse_scores)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('MSE Scores over Iterations')\n",
    "plt.show()\n",
    "\n",
    "# Print the lowest MSE and the best regressor's features\n",
    "print('Lowest MSE:', lowest_mse)\n",
    "print('Features:', X.columns)\n",
    "print('Best Regressor:', best_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb434a-453e-4aaa-8777-0d627c88c4b4",
   "metadata": {},
   "source": [
    "The numbers were all better than the initial ones. Values of previous work and comparison are in presentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
